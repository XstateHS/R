---
title: "Упражнение 8"
author: "Дунашов Константин"
date: "12 05 2021"
output: html_document
---

# Задание:

Построить две модели для прогноза на основе дерева решений:

 -  для непрерывной зависимой переменной;
 -  для категориальной зависимой переменной.

Данные и переменные указаны в таблице с вариантами.
Ядро генератора случайных чисел – номер варианта.

Для каждой модели:

 -  Указать настроечные параметры метода из своего варианта (например: количество узлов, количество предикторов, скорость обучения).
 -  Подогнать модель на обучающей выборке (50% наблюдений). Рассчитать MSE на тестовой выборке.
 -  Перестроить модель с помощью метода, указанного в варианте.
 -  Сделать прогноз по модели с подобранными в п.3 параметрами на тестовой выборке, оценить его точность и построить график «прогноз-реализация».

# Вариант 10

Модели: бэггинг (количество предикторов).
Данные: 'Auto {ISLR}'.

```{r setup, include=FALSE}
library('tree')              # деревья tree()
library('GGally')            # матричный график разброса ggpairs()
library('ISLR')              # набор данных Auto
library('randomForest')      # случайный лес randomForest()
library('gbm')               # бустинг gbm()
library('class')
data(Auto)
knitr::opts_chunk$set(echo = TRUE)
```


```{r }
# Название столбцов переменных
names(Auto)

# Размерность данных
dim(Auto)

# Ядро генератора случайных чисел
my.seed <- 10

```

# Модель 1 (для непрерывной зависимой переменной mpg)

```{r}
# Избавляемся от Name
Auto <- Auto[, -9]

head(Auto)
```

```{r}
# Матричные графики разброса переменных
# Матричные графики разброса переменных
p <- ggpairs(Auto[, c(1, 2:3)])
suppressMessages(print(p))

p <- ggpairs(Auto[, c(1, 4:5)])
suppressMessages(print(p))

p <- ggpairs(Auto[, c(1, 6:8)])
suppressMessages(print(p))
```

```{r}
# Обучающая выборка
set.seed(my.seed)
# Обучающая выборка - 50%
train <- sample(1:nrow(Auto), nrow(Auto)/2)
```

Построим дерево регрессии для зависимой переменной mpg

```{r}
# Обучаем модель
tree.auto <- tree(mpg ~ ., Auto, subset = train)
summary(tree.auto)
```

```{r}
# Визуализация
plot(tree.auto)
text(tree.auto, pretty = 0)
tree.auto                    # Посмотреть всё дерево в консоли
```

```{r}
# Прогноз по модели 
yhat <- predict(tree.auto, newdata = Auto[-train, ])
auto.test <- Auto[-train, "mpg"]

# MSE на тестовой выборке
mse.test <- mean((yhat - auto.test)^2)
names(mse.test)[length(mse.test)] <- 'Auto.regr.tree.all'
mse.test

# Точность прогноза на тестовой выборке
acc.test <- sum(abs(yhat-auto.test))/sum(auto.test)
names(acc.test)[length(acc.test)] <- 'Auto.regr.tree.all'
acc.test
```

# Бэггинг (модель 1)

Используем бэггинг, причем возбмем все 7 предикторов на каждом шаге.

```{r}
# бэггинг с 7 предикторами
set.seed(my.seed)
bag.auto <- randomForest(mpg ~ ., data = Auto, subset = train, 
                           mtry = 7, importance = TRUE)

bag.auto
```

```{r}
# прогноз
yhat.bag = predict(bag.auto, newdata = Auto[-train, ])

# MSE на тестовой
mse.test <- c(mse.test, mean((yhat.bag - auto.test)^2))
names(mse.test)[length(mse.test)] <- 'Auto.bag.model.1.7'
mse.test

# Точность прогноза на тестовой выборке
acc.test <- sum(abs(yhat.bag-auto.test))/sum(auto.test)
names(acc.test)[length(acc.test)] <- 'Auto.regr.tree.model.1.7'
acc.test
```

Ошибка на тестовой выборке равна 7.974. Можно изменить число деревьев с помощью аргумента.

```{r}
# Бэггинг с 7 предикторами и 25 деревьями
bag.auto <- randomForest(mpg ~ ., data = Auto, subset = train,
                           mtry = 7, ntree = 25)

# прогноз
yhat.bag <- predict(bag.auto, newdata = Auto[-train, ])

# MSE на тестовой
mse.test <- c(mse.test, mean((yhat.bag - auto.test)^2))
names(mse.test)[length(mse.test)] <- 'Auto.bag.model.1.7.25'
mse.test

# Точность прогноза на тестовой выборке
acc.test <- c(acc.test, sum(abs(yhat.bag-auto.test))/sum(auto.test))
names(acc.test)[length(acc.test)] <- 'Auto.regr.tree.model.1.7.25'
acc.test
```

```{r}
# График прогноз - реализация
plot(yhat.bag, auto.test)
# линия идеального прогноза
abline(0, 1)
```
Судя по полученным результатам наименьшая MSE наблюдается у модели с использованием бэггинга с 7 предикторами. Минимальная MSE на тестовой выборке равна 7.97, точность прогноза составила 0.08.

# Модель 2 (для категориальной зависимой переменной high.mpg)

Загрузим таблицу с данными по расходу бензина, лошадиной силе и другая информации для автомобилей и добавим к ней переменную high.mpg - миль на галлон:

1, если миля на галлон >= 29;
0 - в противном случае.

```{r}
# Новая переменная
high.mpg <- ifelse(Auto$mpg < 29, '0', '1')
high.mpg <- factor(high.mpg, labels = c('yes', 'no'))

Auto$high.mpg <- high.mpg 

# Название столбцов переменных
names(Auto)
# Размерность данных
dim(Auto)
```

```{r}
# Матричные графики разброса переменных
p <- ggpairs(Auto[, c(9, 1:2)], aes(color = high.mpg))
suppressMessages(print(p))

p <- ggpairs(Auto[, c(9, 3:5)], aes(color = high.mpg))
suppressMessages(print(p))

p <- ggpairs(Auto[, c(9, 6:8)], aes(color = high.mpg))
suppressMessages(print(p))
```

Судя по графикам, класс 0 превосходит по размеру класс 1 по переменной high.mpg приблизительно в 3 раза. Классы на графиках разброса объясняющих переменных сильно смешаны, поэтому модели с непрерывной разрешающей границей вряд ли работают хорошо. Построим дерево для категориального отклика high.mpg, отбросив непрерывный отклик mpg (мы оставили его на первом графике, чтобы проверить, как сработало разделение по значению mpg = 29).

```{r}
# Модель бинарного  дерева
tree.auto <- tree(high.mpg ~ . -mpg, Auto)
summary(tree.auto)

# График результата
plot(tree.auto)                # Ветви
text(tree.auto, pretty = 0)    # Подписи
tree.auto                      # Посмотреть всё дерево в консоли
```

Теперь построим дерево на обучающей выборке и оценим ошибку на тестовой.

```{r}
# Тестовая выборка
Auto.test <- Auto[-train,]
high.mpg.test <- high.mpg[-train]

# Строим дерево на обучающей выборке
tree.auto <- tree(high.mpg ~ . -mpg, Auto, subset = train)

# Делаем прогноз
tree.pred <- predict(tree.auto, Auto.test, type = "class")

# Матрица неточностей
tbl <- table(tree.pred, high.mpg.test)
tbl
# ACC на тестовой
acc.test.2 <- sum(diag(tbl))/sum(tbl)
names(acc.test.2)[length(acc.test.2)] <- 'Auto.class.tree.all.model.2'
acc.test.2
```
Обобщённая характеристика точности: доля верных прогнозов: 0.901.


# Бэггинг (модель 2)

```{r}
set.seed(my.seed)
bag.auto <- randomForest(high.mpg ~ . -mpg, data = Auto, subset = train, 
                           mtry = 7, importance = TRUE)
# График и таблица относительной важности переменных
summary(bag.auto)
```

```{r}
# прогноз
yhat.bag <-  predict(bag.auto, newdata = Auto[-train, ])

# Матрица неточностей
tbl <- table(yhat.bag, high.mpg.test)
tbl

# Точность прогноза на тестовой выборке
acc.test.2 <- c(acc.test.2, sum(diag(tbl))/sum(tbl))
names(acc.test.2)[length(acc.test.2)] <- 'Auto.class.tree.model.2.7'
acc.test.2
```

```{r}
# бэггинг с 7 предикторами и 25 деревьями
bag.auto <- randomForest(high.mpg ~ .-mpg, data = Auto, subset = train,
                           mtry = 7, ntree = 25)

# прогноз
yhat.bag <- predict(bag.auto, newdata = Auto[-train, ])

# Матрица неточностей
tbl <- table(yhat.bag, high.mpg.test)
tbl
# Точность прогноза на тестовой выборке
acc.test.2 <- c(acc.test.2, sum(diag(tbl))/sum(tbl))
names(acc.test.2)[length(acc.test.2)] <- 'Auto.class.tree.model.2.7.25'
acc.test.2
```

```{r}
# График "прогноз - реализация"
plot(yhat.bag, Auto$high.mpg[-train])
```




